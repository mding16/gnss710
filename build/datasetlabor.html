<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <link rel="icon" href="/invisiblebodies/favicon.ico" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="theme-color" content="#000000" />
    <meta
      name="description"
      content="Web site created using create-react-app"
    />
    <link rel="apple-touch-icon" href="%PUBLIC_URL%/logo192.png" />
    <!--
      manifest.json provides metadata used when your web app is installed on a
      user's mobile device or desktop. See https://developers.google.com/web/fundamentals/web-app-manifest/
    -->
    <link rel="manifest" href="%PUBLIC_URL%/manifest.json" />
    <title>DATASET LABOR</title>
    <style>
      body {
        font-family: "Gill Sans", "Gill Sans MT", Calibri, "Trebuchet MS",
          sans-serif;
        background-color: #0000ff;
        padding: 10px;
      }
      .container {
        max-width: 800px;
        margin: 0 auto;
        padding: 20px;
      }
      p {
        color: black;
        text-align: left;
        font-size: 22px;
      }
      .highlight {
        color: white;
      }
      a {
        color: black;
      }
      .highlight1 {
        color: black;
        background-color: magenta;
      }
    </style>
  </head>
  <body>
    <div class="container">
        <p>
            <span class="highlight">Any discussion of artificial intelligence 
                is also a discussion of data. </span>
            Word embedding models like Word2Vec and GloVe convert text to vectors, 
            but in order to do produce meaningful results, they must learn 
            relationships between words from real human language, or text data.
            One major source of data is 
            <a href="https://www.wikipedia.org/" target="_blank">Wikipedia,
            </a>“a free online encyclopedia, 
            created and edited by volunteers around the world and hosted by the 
            Wikimedia Foundation.”
            <br></br>
            <span class="highlight">The labor involved in producing, writing, and curating the text that fuels 
                language models is often rendered invisible in actual dialogue about 
                the model or its results.</span>
            
            <span class="highlight1">
                One organization that conducts this unseen labor is 
                <a href="https://artandfeminism.org/" target="_blank">
                    Art+Feminism
                </a>, 
                a “community of activists that is committed to closing information gaps 
                related to gender, feminism, and the arts, beginning with Wikipedia.” </span>
            
             According to a 2011 Wikimedia Foundation survey, 
             “less than 10% of its contributors identify as female” and 
             “the data relative to trans and non-binary editors is 
             basically non-existent.”  In response, Art+Feminism, in 
             partnership with other organizations like Asia Art Archive 
             and M+, organize Wikipedia Edit-a-thons that support participants 
             in editing and improving content on Wikipedia. 
             Algorithmic bias such as gender bias in word embeddings is commonly 
             attributed to embedded biases in training datasets like
              those from Wikipedia. Efforts to debias the model
              (like 
              <a href="https://arxiv.org/abs/1607.06520" target="_blank">Bolukbasi et al. 2016</a>) often attempt to “modify the underlying data” 
              through mathematical operations on its vectorized form. 
               This page aims to draw attention to incredibly valuable 
               labor that is doing the same modification, but directly at the source. 
            </p>
        </div>
  </body>
</html>
